import OpenAI from 'openai';

// API Configuration
// Current: artemox.com API with $1 budget
// Alternative: all-team-models API (https://all-team-models.com)
// Budget: $1 - Monitor usage at https://artemox.com/ui
// Username: z2076wfx296ge02ijsxytwj@artemox.com
// Password: y2n6GiUlDMmZb3HwT5fFKq9z

const openai = new OpenAI({
  apiKey: 'sk-SDaGmRLAuD9ZleyqqgPawQ',
  baseURL: 'https://api.artemox.com/v1',
  dangerouslyAllowBrowser: true,
  defaultHeaders: {
    'HTTP-Referer': 'https://namestudio.ai',
    'X-Title': 'NAME STUDIO AI'
  }
});

export type AIMode = 'code' | 'ask' | 'plan';

export interface AIMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

export interface FileEdit {
  path: string;
  action: 'create' | 'edit' | 'delete';
  content?: string;
  oldContent?: string;
}

export interface AgentContext {
  task: string;
  current_file?: string;
  cursor_position?: number;
  file_content?: string;
  open_files?: any[];
  project_tree?: any[];
  dependencies?: string[];
  errors?: any[];
  git_diff?: string;
}

export interface AgentResponse {
  analysis: string;
  plan: string[];
  patches: Array<{
    file: string;
    diff: string;
  }>;
  new_files: Array<{
    path: string;
    content: string;
  }>;
  commands: string[];
  notes: string;
  risks?: string[];
  steps?: Array<{
    description: string;
    status: 'pending' | 'in_progress' | 'completed' | 'failed';
    files_affected?: string[];
  }>;
}

export interface ProjectAnalysis {
  structure: any[];
  dependencies: string[];
  entry_points: string[];
  dead_code: string[];
  duplications: Array<{
    files: string[];
    similarity: number;
  }>;
  potential_errors: Array<{
    file: string;
    line: number;
    message: string;
  }>;
  architecture_notes: string;
}

export class AIService {
  private conversationHistory: AIMessage[] = [];
  private currentMode: AIMode = 'code';

  setMode(mode: AIMode) {
    this.currentMode = mode;
  }

  getMode(): AIMode {
    return this.currentMode;
  }

  async chat(userMessage: string, context?: { files?: any[], currentFile?: string }): Promise<string> {
    const systemPrompt = this.getSystemPrompt(context);
    
    this.conversationHistory.push({
      role: 'user',
      content: userMessage
    });

    try {
      const response = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          ...this.conversationHistory
        ],
        temperature: 0.15,
        max_tokens: 8000,
        stream: false
      });

      const assistantMessage = response.choices[0].message.content || '';
      
      this.conversationHistory.push({
        role: 'assistant',
        content: assistantMessage
      });

      return assistantMessage;
    } catch (error: any) {
      console.error('AI Service Error:', error);
      
      if (error?.status === 429) {
        throw new Error('‚ö†Ô∏è API Quota Exceeded: Your OpenRouter API key has reached its usage limit. Please check your OpenRouter account.');
      } else if (error?.status === 401) {
        throw new Error('üîë Invalid API Key: The OpenRouter API key is invalid or has been revoked. Please check your key in the settings.');
      } else if (error?.status === 500 || error?.status === 503) {
        throw new Error('üîß Server Error: OpenRouter servers are currently unavailable. Please try again in a few moments.');
      } else if (error?.message?.includes('network') || error?.message?.includes('fetch')) {
        throw new Error('üåê Network Error: Unable to connect to OpenRouter. Please check your internet connection.');
      }
      
      throw new Error(`‚ùå AI Error: ${error?.message || 'Unknown error occurred'}`);
    }
  }

  async chatStream(
    userMessage: string, 
    context?: AgentContext,
    onChunk?: (chunk: string) => void
  ): Promise<string> {
    const systemPrompt = this.getAgentSystemPrompt();
    
    const agentContext = context ? JSON.stringify(context, null, 2) : '';
    const fullMessage = agentContext ? `${agentContext}\n\nTask: ${userMessage}` : userMessage;
    
    this.conversationHistory.push({
      role: 'user',
      content: fullMessage
    });

    try {
      const stream = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          ...this.conversationHistory
        ],
        temperature: 0.15,
        max_tokens: 8000,
        stream: true
      });

      let fullResponse = '';
      
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content) {
          fullResponse += content;
          if (onChunk) {
            onChunk(content);
          }
        }
      }
      
      this.conversationHistory.push({
        role: 'assistant',
        content: fullResponse
      });

      return fullResponse;
    } catch (error: any) {
      console.error('AI Service Error:', error);
      
      if (error?.status === 429) {
        throw new Error('‚ö†Ô∏è API Quota Exceeded: Your OpenRouter API key has reached its usage limit.');
      } else if (error?.status === 401) {
        throw new Error('üîë Invalid API Key: The OpenRouter API key is invalid or has been revoked.');
      } else if (error?.status === 500 || error?.status === 503) {
        throw new Error('üîß Server Error: OpenRouter servers are currently unavailable. Please try again.');
      } else if (error?.message?.includes('network') || error?.message?.includes('fetch')) {
        throw new Error('üåê Network Error: Unable to connect to OpenRouter. Check your internet connection.');
      }
      
      throw new Error(`‚ùå AI Error: ${error?.message || 'Unknown error occurred'}`);
    }
  }

  async analyzeAndEditFiles(userRequest: string, files: any[]): Promise<FileEdit[]> {
    const prompt = `You are NAME MODEL, an AI coding assistant. Analyze the user's request and determine what file changes are needed.

User Request: ${userRequest}

Available Files:
${files.map(f => `- ${f.path} (${f.language})`).join('\n')}

Respond with a JSON array of file edits in this format:
[
  {
    "path": "file/path.ts",
    "action": "edit" | "create" | "delete",
    "content": "new file content" (for edit/create),
    "explanation": "why this change is needed"
  }
]`;

    try {
      const response = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: 'You are a code editing AI. Respond only with valid JSON.' },
          { role: 'user', content: prompt }
        ],
        temperature: 0.3
      });

      const content = response.choices[0].message.content || '[]';
      const edits = JSON.parse(content);
      return edits;
    } catch (error: any) {
      console.error('File analysis error:', error);
      
      // Return empty array but log the error for debugging
      if (error?.status === 429) {
        console.warn('API quota exceeded during file analysis');
      }
      
      return [];
    }
  }

  private getSystemPrompt(context?: { files?: any[], currentFile?: string }): string {
    const basePrompt = `–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –≤ IDE NAME STUDIO AI.

## –¢–í–û–Ø –†–û–õ–¨:
–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–∞. –û–±—â–∞–π—Å—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –æ–ø—ã—Ç–Ω—ã–π –∫–æ–ª–ª–µ–≥–∞.

## –ß–¢–û –¢–´ –£–ú–ï–ï–®–¨:
- üí¨ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –∫–æ–¥–µ –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏
- üí° –û–±—ä—è—Å–Ω—è—Ç—å –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º
- üêõ –ü–æ–º–æ–≥–∞—Ç—å –Ω–∞—Ö–æ–¥–∏—Ç—å –∏ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –±–∞–≥–∏
- ‚ú® –ü—Ä–µ–¥–ª–∞–≥–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–¥–∞
- üìö –î–∞–≤–∞—Ç—å —Å–æ–≤–µ—Ç—ã –ø–æ best practices
- üîß –ü–æ–º–æ–≥–∞—Ç—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –ø—Ä–æ–µ–∫—Ç–æ–≤
- üöÄ –ü—Ä–µ–¥–ª–∞–≥–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è

## –°–¢–ò–õ–¨ –û–ë–©–ï–ù–ò–Ø:
- –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º
- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
- –î–∞–≤–∞–π –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ
- –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ - —É—Ç–æ—á–Ω–∏

## –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´:
${this.currentMode === 'code' ? 'üîß **CODE MODE** - –¢—ã –º–æ–∂–µ—à—å –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞' : ''}
${this.currentMode === 'ask' ? 'üí¨ **ASK MODE** - –¢—ã –æ–±—ä—è—Å–Ω—è–µ—à—å, –Ω–æ –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å –∏–∑–º–µ–Ω–µ–Ω–∏—è' : ''}
${this.currentMode === 'plan' ? 'üìã **PLAN MODE** - –¢—ã –ø–ª–∞–Ω–∏—Ä—É–µ—à—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π' : ''}

–û–±—â–∞–π—Å—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫. –ü–æ–º–æ–≥–∞–π —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏.`;

    if (context?.files && context.files.length > 0) {
      return `${basePrompt}

üìÅ **–û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã:**
${context.files.map(f => `- ${f.name} (${f.language})`).join('\n')}

üìù **–¢–µ–∫—É—â–∏–π —Ñ–∞–π–ª:** ${context.currentFile ? context.files.find(f => f.path === context.currentFile)?.name || 'None' : 'None'}`;
    }

    return basePrompt;
  }

  private getAgentSystemPrompt(): string {
    return `You are a professional autonomous IDE coding agent operating inside a developer environment.

Your job is to modify real production code safely and minimally.

CORE RULES:

1. NEVER output full files unless explicitly requested.
2. ALWAYS return unified diff patches for modifications.
3. Only modify code relevant to the task.
4. Preserve formatting, code style, naming conventions.
5. Do not hallucinate APIs, functions, or libraries.
6. Do not rename files or restructure folders unless instructed.
7. Avoid unnecessary refactoring.
8. Respect existing architecture and patterns.
9. Prefer small safe changes over large rewrites.
10. If unsure ‚Äî make minimal safe assumptions.

WORKFLOW:

Step 1 ‚Äî analyze project context
Step 2 ‚Äî understand developer intent
Step 3 ‚Äî create a minimal execution plan
Step 4 ‚Äî generate diff patches
Step 5 ‚Äî verify changes logically before output

OUTPUT FORMAT MUST BE JSON:

{
  "analysis": "what you understood from the task",
  "plan": ["step1", "step2", "step3"],
  "patches": [
    {
      "file": "path/to/file.ts",
      "diff": "--- a/path/to/file.ts\\n+++ b/path/to/file.ts\\n@@ -10,3 +10,3 @@\\n- old line\\n+ new line"
    }
  ],
  "new_files": [
    {
      "path": "path/to/new/file.ts",
      "content": "file content here"
    }
  ],
  "commands": ["npm install package"],
  "notes": "brief explanation of changes"
}

PATCH FORMAT (unified diff):

--- a/file.py
+++ b/file.py
@@ -10,3 +10,3 @@
- old line
+ new line

BEHAVIOR:

- Think like a senior engineer.
- You are inside a real IDE.
- Code must compile logically.
- Never invent missing files.
- Never produce pseudo code.
- Never produce explanations outside JSON.
- Always respond with valid JSON only.

You are an autonomous coding agent designed for vibe-coding workflows.`;
  }

  async analyzeProject(projectPath: string): Promise<ProjectAnalysis> {
    const systemPrompt = `You are a code analysis AI. Analyze the project structure and return detailed insights.

Analyze for:
- Project structure and organization
- Dependencies and imports
- Entry points (main files)
- Dead code (unused functions/variables)
- Code duplications
- Potential errors and bugs
- Architecture patterns

Respond with valid JSON only in this format:
{
  "structure": [],
  "dependencies": [],
  "entry_points": [],
  "dead_code": [],
  "duplications": [],
  "potential_errors": [],
  "architecture_notes": ""
}`;

    try {
      const response = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Analyze project at: ${projectPath}` }
        ],
        temperature: 0.2,
        max_tokens: 8000
      });

      const content = response.choices[0].message.content || '{}';
      const analysis = JSON.parse(content);
      return analysis;
    } catch (error) {
      console.error('Project analysis error:', error);
      return {
        structure: [],
        dependencies: [],
        entry_points: [],
        dead_code: [],
        duplications: [],
        potential_errors: [],
        architecture_notes: 'Analysis failed'
      };
    }
  }

  async generateTests(filePath: string, fileContent: string): Promise<string> {
    const systemPrompt = `You are a test generation AI. Generate comprehensive unit tests for the given code.

Requirements:
- Use appropriate testing framework
- Cover edge cases
- Test error handling
- Include setup/teardown if needed
- Follow best practices

Return only the test code, no explanations.`;

    try {
      const response = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Generate tests for:\n\nFile: ${filePath}\n\n${fileContent}` }
        ],
        temperature: 0.2,
        max_tokens: 8000
      });

      return response.choices[0].message.content || '';
    } catch (error) {
      console.error('Test generation error:', error);
      throw new Error('Failed to generate tests');
    }
  }

  async explainCode(code: string, context?: string): Promise<string> {
    const systemPrompt = `You are a code explanation AI. Explain code clearly and concisely.

Focus on:
- What the code does
- How it works
- Key patterns used
- Potential issues
- Suggestions for improvement`;

    try {
      const response = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `${context ? `Context: ${context}\n\n` : ''}Explain this code:\n\n${code}` }
        ],
        temperature: 0.3,
        max_tokens: 4000
      });

      return response.choices[0].message.content || '';
    } catch (error) {
      console.error('Code explanation error:', error);
      throw new Error('Failed to explain code');
    }
  }

  async fixError(errorMessage: string, code: string, filePath: string): Promise<AgentResponse> {
    const systemPrompt = this.getAgentSystemPrompt();
    
    const context: AgentContext = {
      task: `Fix this error: ${errorMessage}`,
      current_file: filePath,
      file_content: code,
      errors: [{ message: errorMessage, file: filePath }]
    };

    try {
      const response = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: JSON.stringify(context, null, 2) }
        ],
        temperature: 0.15,
        max_tokens: 8000
      });

      const content = response.choices[0].message.content || '{}';
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
      
      throw new Error('Invalid response format');
    } catch (error) {
      console.error('Error fixing error:', error);
      throw error;
    }
  }

  async refactorCode(code: string, filePath: string, instructions?: string): Promise<AgentResponse> {
    const systemPrompt = this.getAgentSystemPrompt();
    
    const context: AgentContext = {
      task: instructions || 'Refactor this code to improve quality, readability, and maintainability',
      current_file: filePath,
      file_content: code
    };

    try {
      const response = await openai.chat.completions.create({
        model: 'qwen/qwen-2.5-coder-32b-instruct',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: JSON.stringify(context, null, 2) }
        ],
        temperature: 0.15,
        max_tokens: 8000
      });

      const content = response.choices[0].message.content || '{}';
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
      
      throw new Error('Invalid response format');
    } catch (error) {
      console.error('Refactoring error:', error);
      throw error;
    }
  }

  clearHistory() {
    this.conversationHistory = [];
  }

  getHistory(): AIMessage[] {
    return this.conversationHistory;
  }
}

export const aiService = new AIService();
